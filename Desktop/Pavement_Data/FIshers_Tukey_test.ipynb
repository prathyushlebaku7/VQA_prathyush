{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean crash rates:\n",
      " IRI_Category\n",
      "Good     34.007985\n",
      "Fair    161.138578\n",
      "Poor    414.560873\n",
      "Name: Crash_Frequency, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/h3jt_tns2s14c8y5w9qptb6c0000gn/T/ipykernel_65825/3680048420.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['IRI_Category'] = pd.cut(pd.to_numeric(df['IRI'], errors='coerce'), bins=iri_bins, labels=iri_labels)\n"
     ]
    }
   ],
   "source": [
    "#Finding Mean crash rate \n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"/Users/lebakuprathyushkumarreddy/Desktop/Prof_Lu_Gao/Crash_Data_(SOR)_2022_IRI_others.csv\")\n",
    "# Preprocess data\n",
    "data[\"IRI\"].fillna(df[\"IRI\"].mean(), inplace=True)\n",
    "data['Crash_Frequency'].fillna(df['Crash_Frequency'].mean(),inplace=True)\n",
    "\n",
    "df = data[data[\"LIGHT\"] == 1]    #subset of the data for different road conditions\n",
    "\n",
    "iri_bins = [0, 95, 170, float('inf')]\n",
    "iri_labels = ['Good', 'Fair', 'Poor']\n",
    "\n",
    "df['IRI_Category'] = pd.cut(pd.to_numeric(df['IRI'], errors='coerce'), bins=iri_bins, labels=iri_labels)\n",
    "\n",
    "# Calculate mean crash rates for each IRI category\n",
    "mean_crash_rates = df.groupby('IRI_Category')['Crash_Frequency'].mean()\n",
    "print(\"Mean crash rates:\\n\", mean_crash_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison between 'Good' and 'Fair': LSD = 66.5520 (significant), p-value = 0.0000\n",
      "Value of LSD: 66.55200803081932\n",
      "Value of Crirical LSD: 3.7441502377394067\n",
      "Comparison between 'Good' and 'Poor': LSD = 9.5024 (not significant), p-value = 0.0000\n",
      "Value of LSD: 9.502433284961862\n",
      "Value of Crirical LSD: 26.222832533322766\n",
      "Comparison between 'Fair' and 'Poor': LSD = 9.4988 (not significant), p-value = 0.0000\n",
      "Value of LSD: 9.498800340680821\n",
      "Value of Crirical LSD: 26.232861809238447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/h3jt_tns2s14c8y5w9qptb6c0000gn/T/ipykernel_65825/2933467852.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['IRI_Category'] = pd.cut(pd.to_numeric(df['IRI'], errors='coerce'), bins=iri_bins, labels=iri_labels)\n"
     ]
    }
   ],
   "source": [
    "#Fishers LSD Test \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f, t\n",
    "\n",
    "# Load your DataFrame\n",
    "data= pd.read_csv(\"/Users/lebakuprathyushkumarreddy/Desktop/Prof_Lu_Gao/Crash_Data_(SOR)_2022_IRI_others.csv\")\n",
    "data[\"IRI\"].fillna(df[\"IRI\"].mean(), inplace=True)\n",
    "data['Crash_Frequency'].fillna(df['Crash_Frequency'].mean(),inplace=True)\n",
    "\n",
    "df = data[data[\"LIGHT\"] == 1]\n",
    "\n",
    "\n",
    "# Define your IRI bins and labels\n",
    "iri_bins = [0, 95, 170, float('inf')]\n",
    "iri_labels = ['Good', 'Fair', 'Poor']\n",
    "\n",
    "# Create a new column 'IRI_Category' based on binning\n",
    "df['IRI_Category'] = pd.cut(pd.to_numeric(df['IRI'], errors='coerce'), bins=iri_bins, labels=iri_labels)\n",
    "\n",
    "# Perform ANOVA to test for overall group differences\n",
    "groups = [df[df['IRI_Category'] == label]['Crash_Frequency'] for label in iri_labels]\n",
    "n_groups = len(groups)\n",
    "n_total = len(df['Crash_Frequency'])\n",
    "n_obs = [len(group) for group in groups]\n",
    "mean_group = [group.mean() for group in groups]\n",
    "overall_mean = df['Crash_Frequency'].mean()\n",
    "\n",
    "# Calculate the sum of squares between groups (SSB)\n",
    "SSB = sum([n * (mean - overall_mean)**2 for n, mean in zip(n_obs, mean_group)])\n",
    "\n",
    "# Calculate the mean square between groups (MSB)\n",
    "MSB = SSB / (n_groups - 1)\n",
    "\n",
    "# Calculate the mean square error (MSE)\n",
    "SSE = sum([(n - 1) * group.var() for n, group in zip(n_obs, groups)])\n",
    "MSE = SSE / (n_total - n_groups)\n",
    "\n",
    "# Calculate the F-statistic\n",
    "F = MSB / MSE\n",
    "\n",
    "# Calculate the critical value from the F-distribution\n",
    "alpha = 0.05\n",
    "df1 = n_groups - 1\n",
    "df2 = n_total - n_groups\n",
    "critical_value = f.ppf(1 - alpha, df1, df2)\n",
    "\n",
    "# Perform pairwise comparisons using Fisher's LSD and calculate p-values\n",
    "from itertools import combinations\n",
    "pairwise_comparisons = list(combinations(iri_labels, 2))\n",
    "for label1, label2 in pairwise_comparisons:\n",
    "    group1 = df[df['IRI_Category'] == label1]['Crash_Frequency']\n",
    "    group2 = df[df['IRI_Category'] == label2]['Crash_Frequency']\n",
    "    \n",
    "    # Calculate the pooled standard error\n",
    "    pooled_var = ((n_obs[0] - 1) * group1.var() + (n_obs[1] - 1) * group2.var()) / (n_obs[0] + n_obs[1] - 2)\n",
    "    pooled_se = np.sqrt(pooled_var * (1/n_obs[0] + 1/n_obs[1]))\n",
    "    \n",
    "    # Calculate the LSD\n",
    "    lsd = abs(mean_group[0] - mean_group[1]) / pooled_se\n",
    "    # Calculate the critical LSD value\n",
    "    critical_lsd = t.ppf(1 - alpha/2, df2) * pooled_se\n",
    "   \n",
    "    # Calculate the p-value\n",
    "    p_value = 2 * (1 - t.cdf(abs(lsd), df2))\n",
    "    \n",
    "    if lsd > critical_lsd:\n",
    "        print(f\"Comparison between '{label1}' and '{label2}': LSD = {lsd:.4f} (significant), p-value = {p_value:.4f}\")\n",
    "        print(f\"Value of LSD: {lsd}\")\n",
    "        print(f\"Value of Crirical LSD: {critical_lsd}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Comparison between '{label1}' and '{label2}': LSD = {lsd:.4f} (not significant), p-value = {p_value:.4f}\")\n",
    "        print(f\"Value of LSD: {lsd}\")\n",
    "        print(f\"Value of Crirical LSD: {critical_lsd}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      "group1 group2  meandiff p-adj   lower     upper   reject\n",
      "--------------------------------------------------------\n",
      "  Fair   Good -123.1598   0.0 -129.8388 -116.4808   True\n",
      "  Fair   Poor  256.4614   0.0   247.832  265.0909   True\n",
      "  Good   Poor  379.6213   0.0  369.0889  390.1536   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Tukey Kramer Test\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"/Users/lebakuprathyushkumarreddy/Desktop/Prof_Lu_Gao/Crash_Data_(SOR)_2022_IRI_others.csv\")\n",
    "df[\"IRI\"].fillna(df[\"IRI\"].mean(), inplace=True)\n",
    "df['Crash_Frequency'].fillna(df['Crash_Frequency'].mean(),inplace=True)\n",
    "\n",
    "# Define your IRI bins and labels\n",
    "iri_bins = [0, 95, 170, float('inf')]\n",
    "iri_labels = ['Good', 'Fair', 'Poor']\n",
    "\n",
    "# Create a new column 'IRI_Category' based on binning\n",
    "df['IRI_Category'] = pd.cut(pd.to_numeric(df['IRI'], errors='coerce'), bins=iri_bins, labels=iri_labels)\n",
    "\n",
    "# Perform Tukey-Kramer test\n",
    "tukey_results = pairwise_tukeyhsd(endog=df['Crash_Frequency'], groups=df['IRI_Category'], alpha=0.05)\n",
    "\n",
    "# Extract p-values from the summary\n",
    "print(tukey_results.summary())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
