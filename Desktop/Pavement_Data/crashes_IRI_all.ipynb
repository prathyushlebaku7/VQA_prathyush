{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xml(path):\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    return root\n",
    "\n",
    "def get_placemarks(root):\n",
    "    return root.findall('.//{http://www.opengis.net/kml/2.2}Placemark')\n",
    "\n",
    "def get_line_strings(placemark):\n",
    "    return placemark.findall('.//{http://www.opengis.net/kml/2.2}LineString')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pavement.xml file\n",
    "xml_file = 'Pavement.xml'\n",
    "xml_root = read_xml(xml_file)\n",
    "placemarks = get_placemarks(xml_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestring_list = []\n",
    "for placemark in placemarks:\n",
    "    line_strings = get_line_strings(placemark)\n",
    "    temp = line_strings[0].findall('.//{http://www.opengis.net/kml/2.2}coordinates')[0].text.split(',0')[:-1]\n",
    "    linestring_list.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Points(placemark):\n",
    "    return placemark.findall('.//{http://www.opengis.net/kml/2.2}Point')\n",
    "\n",
    "# <Placemark>\n",
    "# \t<ExtendedData><SchemaData schemaUrl=\"#CRASH_CRASH\">\n",
    "# \t\t<SimpleData name=\"OBJECTID\">2181450</SimpleData>\n",
    "# \t\t<SimpleData name=\"CRASH_KEY\">2009000003</SimpleData>\n",
    "# \t\t<SimpleData name=\"CASENUMBER\">2009482002</SimpleData>\n",
    "# \t\t<SimpleData name=\"LECASENUM\">W09-000195</SimpleData>\n",
    "# \t\t<SimpleData name=\"CRASH_DATE\">2009/01/01 00:00:00+00</SimpleData>\n",
    "# \t\t<SimpleData name=\"CRASH_MONTH\">1</SimpleData>\n",
    "# \t\t<SimpleData name=\"CRASH_DAY\">5</SimpleData>\n",
    "# \t\t<SimpleData name=\"TIMESTR\">13:11</SimpleData>\n",
    "# \t\t<SimpleData name=\"DISTRICT\">2</SimpleData>\n",
    "# \t\t<SimpleData name=\"COUNTY_NUMBER\">7</SimpleData>\n",
    "# \t\t<SimpleData name=\"LITERAL\">WILLISTON AVE &amp; W 9TH ST</SimpleData>\n",
    "# </Placemark>\n",
    "\n",
    "# get crash date from xml file and get only year\n",
    "def get_crash_date(placemark):\n",
    "    return placemark.findall('.//{http://www.opengis.net/kml/2.2}SimpleData')[4].text.split('/')[0]\n",
    "\n",
    "def get_objectid(placemark):\n",
    "    return placemark.findall('.//{http://www.opengis.net/kml/2.2}SimpleData')[0].text\n",
    "\n",
    "def get_crcomnnr(placemark):\n",
    "    return placemark.findall('.//{http://www.opengis.net/kml/2.2}SimpleData')[13].text\n",
    "def get_csev(placemark):\n",
    "    return placemark.findall('.//{http://www.opengis.net/kml/2.2}SimpleData')[23].text\n",
    "\n",
    "def get_csrfcnd(placemark):\n",
    "    return placemark.findall('.//{http://www.opengis.net/kml/2.2}SimpleData')[18].text\n",
    "\n",
    "def get_light(placemark):\n",
    "    return placemark.findall('.//{http://www.opengis.net/kml/2.2}SimpleData')[17].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53599\n"
     ]
    }
   ],
   "source": [
    "xmk_file_crash = \"Crash_Data_2022.xml\"\n",
    "xml_root_crash = read_xml(xmk_file_crash)\n",
    "placemarks_crash = get_placemarks(xml_root_crash)\n",
    "print(len(placemarks_crash))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52976\n"
     ]
    }
   ],
   "source": [
    "crash_df = pd.read_csv('Crash_Data_(SOR)_2022.csv')\n",
    "print(len(crash_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-d79aaa7556e2>:2: DtypeWarning: Columns (11,87,99,115,116,119,120,121,122,123,131,132,147,148,150,151,152,153,154,155,156,185,186,187,188,192,193,194,195,196,199,200,201,202,209,210,211,212,215,218,219,225) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pavement_df = pd.read_csv('Pavement_with_crashes_2022_cf.csv')\n"
     ]
    }
   ],
   "source": [
    "# pavement_df = pd.read_csv('Pavement.csv')\n",
    "pavement_df = pd.read_csv('Pavement_with_crashes_2022_cf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_list = []\n",
    "i=0\n",
    "for placemark in placemarks_crash:\n",
    "    year = get_crash_date(placemark)\n",
    "    id = get_objectid(placemark)\n",
    "    points = get_Points(placemark)\n",
    "    if year == '2022':\n",
    "        if len(points)==0:\n",
    "            continue\n",
    "        x,y,z = points[0].findall('.//{http://www.opengis.net/kml/2.2}coordinates')[0].text.split(',')\n",
    "        id =int(id)\n",
    "        x = float(x)\n",
    "        y = float(y)\n",
    "        temp =(id,x,y)\n",
    "        points_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53599\n"
     ]
    }
   ],
   "source": [
    "print(len(points_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52930\n"
     ]
    }
   ],
   "source": [
    "\n",
    "objectid_list = []\n",
    "for i in range(len(crash_df)):\n",
    "    objectid_list.append(crash_df['OBJECTID'][i])\n",
    "points_id_list = []\n",
    "for i in range(len(points_list)):\n",
    "    points_id_list.append(points_list[i][0])\n",
    "intersection = set(objectid_list).intersection(set(points_id_list))\n",
    "print(len(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# use this with tolerance instead of exact match\n",
    "iri_dict = {}\n",
    "pci={}\n",
    "crack={}\n",
    "fault={}\n",
    "rut={}\n",
    "frict={}\n",
    "crash_freq={}\n",
    "for i in range(len(points_list)):\n",
    "    id,x,y = points_list[i]\n",
    "    for line_string in linestring_list:\n",
    "        for j in range(len(line_string)):\n",
    "          # keep some tolerance instead of exact match\n",
    "            x1,y1 = line_string[j].split(',')\n",
    "            x1 = float(x1)\n",
    "            y1 = float(y1)\n",
    "            if abs(x1-x) < 0.0002 and abs(y1-y) < 0.0002:\n",
    "                iri_dict[id] = pavement_df['IRI'][j]\n",
    "                pci[id] = pavement_df['PCI_2'][j]\n",
    "                crack[id] = pavement_df['CRACK_INDX'][j]\n",
    "                fault[id] = pavement_df['FAULT_INDX'][j]\n",
    "                rut[id] = pavement_df['RUT'][j]\n",
    "                frict[id] = pavement_df['FRICT'][j]\n",
    "                crash_freq[id] = pavement_df['Crash_Frequency'][j]\n",
    "                print(i)\n",
    "                break\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add iri to crash_df\n",
    "iri_list = []\n",
    "pci_list = []\n",
    "crack_list = []\n",
    "fault_list = []\n",
    "rut_list = []\n",
    "frict_list = []\n",
    "crash_freq_list = []\n",
    "for i in range(len(crash_df)):\n",
    "    id = crash_df['OBJECTID'][i]\n",
    "    if id in iri_dict.keys():\n",
    "        iri_list.append(iri_dict[id])\n",
    "        pci_list.append(pci[id])\n",
    "        crack_list.append(crack[id])\n",
    "        fault_list.append(fault[id])\n",
    "        rut_list.append(rut[id])\n",
    "        frict_list.append(frict[id])\n",
    "        crash_freq_list.append(crash_freq[id])\n",
    "\n",
    "    else:\n",
    "        iri_list.append('NA')\n",
    "        pci_list.append('NA')\n",
    "        crack_list.append('NA')\n",
    "        fault_list.append('NA')\n",
    "        rut_list.append('NA')\n",
    "        frict_list.append('NA')\n",
    "        crash_freq_list.append('NA')\n",
    "\n",
    "\n",
    "crash_df['IRI'] = iri_list\n",
    "crash_df['PCI_2'] = pci_list\n",
    "crash_df['CRACK_INDX'] = crack_list\n",
    "crash_df['FAULT_INDX'] = fault_list\n",
    "crash_df['RUT'] = rut_list\n",
    "crash_df['FRICT'] = frict_list\n",
    "crash_df['Crash_Frequency'] = crash_freq_list\n",
    "crash_df.to_csv('Crash_Data_(SOR)_2022_IRI_others.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
